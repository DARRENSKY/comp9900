relevantTable={
  "Neural Network Dark Ages": [
    "Neural Network Origins",
    "Neural Network Renaissance"
  ],
  "Neural Network Renaissance": [
    "Neural Network Origins",
    "Neural Network Dark Ages"
  ],
  "Applications of Deep Learning": [
    "Deep Learning",
    "History of Deep Learning"
  ],
  "History of Deep Learning": [
    "Deep Learning",
    "Applications of Deep Learning"
  ],
  "Structure of a Typical Neuron": [
    "Neurons as Body Cells",
    "Neurons versus Body Cells",
    "Variety of Neuron Types"
  ],
  "Neurons versus Body Cells": [
    "Neurons as Body Cells",
    "Structure of a Typical Neuron",
    "Variety of Neuron Types"
  ],
  "Variety of Neuron Types": [
    "Neurons as Body Cells",
    "Structure of a Typical Neuron",
    "Neurons versus Body Cells"
  ],
  "Synapses and Ion Channels": [
    "Synapse",
    "Ion Channel"
  ],
  "Ion Channel": [
    "Synapse",
    "Synapses and Ion Channels"
  ],
  "Perceptron Learning Example": [
    "Perceptron Learning Rule",
    "Training Step 1",
    "Training Step 2",
    "Training Step 3",
    "Final Outcome",
    "Limitations of Perceptrons"
  ],
  "Training Step 1": [
    "Perceptron Learning Rule",
    "Perceptron Learning Example",
    "Training Step 2",
    "Training Step 3",
    "Final Outcome",
    "Limitations of Perceptrons"
  ],
  "Training Step 2": [
    "Perceptron Learning Rule",
    "Perceptron Learning Example",
    "Training Step 1",
    "Training Step 3",
    "Final Outcome",
    "Limitations of Perceptrons"
  ],
  "Training Step 3": [
    "Perceptron Learning Rule",
    "Perceptron Learning Example",
    "Training Step 1",
    "Training Step 2",
    "Final Outcome",
    "Limitations of Perceptrons"
  ],
  "Final Outcome": [
    "Perceptron Learning Rule",
    "Perceptron Learning Example",
    "Training Step 1",
    "Training Step 2",
    "Training Step 3",
    "Limitations of Perceptrons"
  ],
  "Limitations of Perceptrons": [
    "Perceptron Learning Rule",
    "Perceptron Learning Example",
    "Training Step 1",
    "Training Step 2",
    "Training Step 3",
    "Final Outcome"
  ],
  "Supervised Learning - Issues": [
    "Supervised Learning"
  ],
  "Two-Layer Neural Network": [
    "Multi-Layer Neural Networks",
    "Neural Network Equations"
  ],
  "Neural Network Equations": [
    "Multi-Layer Neural Networks",
    "Two-Layer Neural Network"
  ],
  "Probability and Logic": [
    "Probability",
    "Probability for Continuous Variables",
    "Joint Probability Distribution",
    "Inference by Enumeration",
    "Conditional Probability",
    "Conditional Probability by Enumeration"
  ],
  "Probability for Continuous Variables": [
    "Probability",
    "Probability and Logic",
    "Joint Probability Distribution",
    "Inference by Enumeration",
    "Conditional Probability",
    "Conditional Probability by Enumeration"
  ],
  "Joint Probability Distribution": [
    "Probability",
    "Probability and Logic",
    "Probability for Continuous Variables",
    "Inference by Enumeration",
    "Conditional Probability",
    "Conditional Probability by Enumeration"
  ],
  "Inference by Enumeration": [
    "Probability",
    "Probability and Logic",
    "Probability for Continuous Variables",
    "Joint Probability Distribution",
    "Conditional Probability",
    "Conditional Probability by Enumeration"
  ],
  "Conditional Probability": [
    "Conditional Probability by Enumeration"
  ],
  "Conditional Probability by Enumeration": [
    "Conditional Probability"
  ],
  "Derivation of Cross Entropy": [
    "Cross Entropy"
  ],
  "Derivation of Least Squares": [
    "Least Squares Line Fitting"
  ],
  "Bayes Rule in Machine Learning": [
    "Bayes' Rule"
  ],
  "N-2-N Encoder": [
    "Encoder Networks",
    "8-3-8 Encoder"
  ],
  "8-3-8 Encoder": [
    "Encoder Networks",
    "N-2-N Encoder"
  ],
  "Solutions to Vanishing Gradients": [
    "Vanishing / Exploding Gradients"
  ],
  "Dropout as an Implicit Ensemble": [
    "Dropout"
  ],
  "Convolutional Filters": [
    "Convolutional Networks",
    "Convolutional Network Components",
    "Convolutional Network Architecture"
  ],
  "Convolutional Network Components": [
    "Convolutional Networks",
    "Convolutional Filters",
    "Convolutional Network Architecture"
  ],
  "Convolutional Network Architecture": [
    "Convolutional Networks",
    "Convolutional Filters",
    "Convolutional Network Components"
  ],
  "Convolutional Neural Networks": [
    "Convolution Operator",
    "Example: LeNet"
  ],
  "Example: LeNet": [
    "Convolution Operator",
    "Convolutional Neural Networks"
  ],
  "Example: LeNet trained on MNIST": [
    "Max Pooling"
  ],
  "Stride Dimensions": [
    "Stride",
    "Stride with Zero Padding"
  ],
  "Stride with Zero Padding": [
    "Stride",
    "Stride Dimensions"
  ],
  "AlexNet Details": [
    "AlexNet Architecture"
  ],
  "Statistics Example: Coin Tossing": [
    "Statistics"
  ],
  "Neural Texture Synthesis": [
    "Texture Synthesis"
  ],
  "NetTalk Task": [
    "NetTalk",
    "NetTalk Architecture"
  ],
  "NetTalk Architecture": [
    "NetTalk",
    "NetTalk Task"
  ],
  "Other Recurrent Network Architectures": [
    "Simple Recurrent Network"
  ],
  "Oscillating Solution for anbn": [
    "Elman Network for predicting anbn",
    "Learning to Predict anbn",
    "Monotonic Solution for anbn",
    "Hidden Unit Analysis for anbn"
  ],
  "Learning to Predict anbn": [
    "Elman Network for predicting anbn",
    "Oscillating Solution for anbn",
    "Monotonic Solution for anbn",
    "Hidden Unit Analysis for anbn"
  ],
  "Monotonic Solution for anbn": [
    "Elman Network for predicting anbn",
    "Oscillating Solution for anbn",
    "Learning to Predict anbn",
    "Hidden Unit Analysis for anbn"
  ],
  "Hidden Unit Analysis for anbn": [
    "Elman Network for predicting anbn",
    "Oscillating Solution for anbn",
    "Learning to Predict anbn",
    "Monotonic Solution for anbn"
  ],
  "Partly Monotonic Solution for anbncn": [
    "Hidden Unit Dynamics for anbncn"
  ],
  "Embedded Reber Grammar": [
    "Reber Grammar"
  ],
  "Gated Recurrent Unit": [
    "Long Short Term Memory"
  ],
  "History of Word Embeddings": [
    "Word Embeddings"
  ],
  "Eigenvalue vs. Singular Value Decomposition": [
    "Singular Value Decomposition"
  ],
  "word2vec 1-Word Context Model": [
    "word2vec and GloVe",
    "word2vec Issues",
    "word2vec Weight Updates",
    "word2vec Weight Updates",
    "word2vec Skip-Gram Model"
  ],
  "word2vec Issues": [
    "word2vec and GloVe",
    "word2vec 1-Word Context Model",
    "word2vec Weight Updates",
    "word2vec Weight Updates",
    "word2vec Skip-Gram Model"
  ],
  "word2vec Weight Updates": [
    "word2vec and GloVe",
    "word2vec 1-Word Context Model",
    "word2vec Issues",
    "word2vec Weight Updates",
    "word2vec Skip-Gram Model"
  ],
  "word2vec Skip-Gram Model": [
    "word2vec and GloVe",
    "word2vec 1-Word Context Model",
    "word2vec Issues",
    "word2vec Weight Updates",
    "word2vec Weight Updates"
  ],
  "Word Analogies": [
    "Word Analogy Task"
  ],
  "Captioning, with Attention": [
    "Attention Mechanism"
  ],
  "Comparing Models of Optimality": [
    "Models of optimality"
  ],
  "Value Function Learning": [
    "Value Function"
  ],
  "Q-Learning Example": [
    "Q-Learning",
    "Theoretical Results",
    "Limitations of Theoretical Results"
  ],
  "Theoretical Results": [
    "Q-Learning",
    "Q-Learning Example",
    "Limitations of Theoretical Results"
  ],
  "Limitations of Theoretical Results": [
    "Q-Learning",
    "Q-Learning Example",
    "Theoretical Results"
  ],
  "Backgammon Neural Network": [
    "Backgammon"
  ],
  "Shock Actuators": [
    "Shock Physics",
    "Shock Sensors",
    "Shock Inputs",
    "Shock Agent",
    "Shock Task"
  ],
  "Shock Sensors": [
    "Shock Physics",
    "Shock Actuators",
    "Shock Inputs",
    "Shock Agent",
    "Shock Task"
  ],
  "Shock Inputs": [
    "Shock Physics",
    "Shock Actuators",
    "Shock Sensors",
    "Shock Agent",
    "Shock Task"
  ],
  "Shock Agent": [
    "Shock Physics",
    "Shock Actuators",
    "Shock Sensors",
    "Shock Inputs",
    "Shock Task"
  ],
  "Shock Task": [
    "Shock Physics",
    "Shock Actuators",
    "Shock Sensors",
    "Shock Inputs",
    "Shock Agent"
  ],
  "Actor Critic Algorithm": [
    "Policy Gradients and Actor-Critic",
    "Advantage Actor Critic",
    "Asynchronous Advantage Actor Critic"
  ],
  "DQN Results for Atari Games": [
    "Deep Q-Learning for Atari Games",
    "DQN Improvements"
  ],
  "DQN Improvements": [
    "Deep Q-Learning for Atari Games",
    "DQN Results for Atari Games"
  ],
  "Advantage Actor Critic": [
    "Policy Gradients and Actor-Critic",
    "Actor Critic Algorithm",
    "Asynchronous Advantage Actor Critic"
  ],
  "Asynchronous Advantage Actor Critic": [
    "Policy Gradients and Actor-Critic",
    "Actor Critic Algorithm",
    "Advantage Actor Critic"
  ],
  "Reverse KL-Divergence": [
    "KL-Divergence",
    "KL-Divergence and Entropy",
    "Forward KL-Divergence",
    ""
  ],
  "KL-Divergence and Entropy": [
    "KL-Divergence",
    "Reverse KL-Divergence",
    "Forward KL-Divergence",
    ""
  ],
  "Forward KL-Divergence": [
    "KL-Divergence",
    "Reverse KL-Divergence",
    "KL-Divergence and Entropy",
    ""
  ],
  "": [
    "KL-Divergence",
    "Reverse KL-Divergence",
    "KL-Divergence and Entropy",
    "Forward KL-Divergence"
  ],
  "Hill-Climbing by Min-Conflicts": [
    "Hill-Climbing"
  ],
  "Boltzmann Distribution": [
    "Boltzmann Machine",
    "Boltzmann Machine Limitations",
    "Restricted Boltzmann Machine",
    "Deep Boltzmann Machine"
  ],
  "Boltzmann Machine Limitations": [
    "Boltzmann Machine",
    "Boltzmann Distribution",
    "Restricted Boltzmann Machine",
    "Deep Boltzmann Machine"
  ],
  "Restricted Boltzmann Machine": [
    "Boltzmann Machine",
    "Boltzmann Distribution",
    "Boltzmann Machine Limitations",
    "Deep Boltzmann Machine"
  ],
  "Deep Boltzmann Machine": [
    "Boltzmann Machine",
    "Boltzmann Distribution",
    "Boltzmann Machine Limitations",
    "Restricted Boltzmann Machine"
  ],
  "Alternating Gibbs Sampling": [
    "Gibbs Sampling"
  ],
  "Quick Contrastive Divergence": [
    "Contrastive Divergence"
  ],
  "Autoencoder as Pretraining": [
    "Autoencoder Networks",
    "Regularized Autoencoders",
    "Sparse Autoencoder",
    "Contractive Autoencoder",
    "Denoising Autoencoder"
  ],
  "Regularized Autoencoders": [
    "Autoencoder Networks",
    "Autoencoder as Pretraining",
    "Sparse Autoencoder",
    "Contractive Autoencoder",
    "Denoising Autoencoder"
  ],
  "Sparse Autoencoder": [
    "Autoencoder Networks",
    "Autoencoder as Pretraining",
    "Regularized Autoencoders",
    "Contractive Autoencoder",
    "Denoising Autoencoder"
  ],
  "Contractive Autoencoder": [
    "Autoencoder Networks",
    "Autoencoder as Pretraining",
    "Regularized Autoencoders",
    "Sparse Autoencoder",
    "Denoising Autoencoder"
  ],
  "Denoising Autoencoder": [
    "Autoencoder Networks",
    "Autoencoder as Pretraining",
    "Regularized Autoencoders",
    "Sparse Autoencoder",
    "Contractive Autoencoder"
  ],
  "Variational Autoencoder Digits": [
    "Variational Autoencoder",
    "Variational Autoencoder Digits",
    "Variational Autoencoder Faces"
  ],
  "Variational Autoencoder Faces": [
    "Variational Autoencoder",
    "Variational Autoencoder Digits",
    "Variational Autoencoder Digits"
  ],
  "Blind Watchmaker Biomorphs": [
    "Blind Watchmaker"
  ],
  "PicBreeder Examples": [
    "PicBreeder"
  ],
  "GAN Generated Images": [
    "GAN Convolutional Architectures",
    "GAN Image Vector Arithmetic",
    "The GAN Zoo",
    "GAN References"
  ],
  "GAN Image Vector Arithmetic": [
    "GAN Convolutional Architectures",
    "GAN Generated Images",
    "The GAN Zoo",
    "GAN References"
  ],
  "The GAN Zoo": [
    "GAN Convolutional Architectures",
    "GAN Generated Images",
    "GAN Image Vector Arithmetic",
    "GAN References"
  ],
  "GAN References": [
    "GAN Convolutional Architectures",
    "GAN Generated Images",
    "GAN Image Vector Arithmetic",
    "The GAN Zoo"
  ],
  "Evolutionary Issues": [
    "Evolutionary Computation"
  ],
  "Co-evolution in Machine Learning": [
    "Co-Evolution in Nature"
  ],
  "Hierarchical Evolutionary Re-Combination Language (HERCL)": [
    "Hierarchical Evolutionary Re-Combination",
    "HERCL Commands"
  ],
  "HERCL Commands": [
    "Hierarchical Evolutionary Re-Combination",
    "Hierarchical Evolutionary Re-Combination Language (HERCL)"
  ],
  "Neural Network Origins": [
    "Neural Network Dark Ages",
    "Neural Network Renaissance"
  ],
  "Deep Learning": [
    "Applications of Deep Learning",
    "History of Deep Learning"
  ],
  "Neurons as Body Cells": [
    "Structure of a Typical Neuron",
    "Neurons versus Body Cells",
    "Variety of Neuron Types"
  ],
  "Synapse": [
    "Synapses and Ion Channels",
    "Ion Channel"
  ],
  "Perceptron Learning Rule": [
    "Perceptron Learning Example",
    "Training Step 1",
    "Training Step 2",
    "Training Step 3",
    "Final Outcome",
    "Limitations of Perceptrons"
  ],
  "Supervised Learning": [
    "Supervised Learning - Issues"
  ],
  "Multi-Layer Neural Networks": [
    "Two-Layer Neural Network",
    "Neural Network Equations"
  ],
  "Probability": [
    "Probability and Logic",
    "Probability for Continuous Variables",
    "Joint Probability Distribution",
    "Inference by Enumeration",
    "Conditional Probability",
    "Conditional Probability by Enumeration"
  ],
  "Cross Entropy": [
    "Derivation of Cross Entropy"
  ],
  "Least Squares Line Fitting": [
    "Derivation of Least Squares"
  ],
  "Bayes' Rule": [
    "Bayes Rule in Machine Learning"
  ],
  "Encoder Networks": [
    "N-2-N Encoder",
    "8-3-8 Encoder"
  ],
  "Vanishing / Exploding Gradients": [
    "Solutions to Vanishing Gradients"
  ],
  "Dropout": [
    "Dropout as an Implicit Ensemble"
  ],
  "Convolutional Networks": [
    "Convolutional Filters",
    "Convolutional Network Components",
    "Convolutional Network Architecture"
  ],
  "Convolution Operator": [
    "Convolutional Neural Networks",
    "Example: LeNet"
  ],
  "Max Pooling": [
    "Example: LeNet trained on MNIST"
  ],
  "Stride": [
    "Stride Dimensions",
    "Stride with Zero Padding"
  ],
  "AlexNet Architecture": [
    "AlexNet Details"
  ],
  "Statistics": [
    "Statistics Example: Coin Tossing"
  ],
  "Texture Synthesis": [
    "Neural Texture Synthesis"
  ],
  "NetTalk": [
    "NetTalk Task",
    "NetTalk Architecture"
  ],
  "Simple Recurrent Network": [
    "Other Recurrent Network Architectures"
  ],
  "Elman Network for predicting anbn": [
    "Oscillating Solution for anbn",
    "Learning to Predict anbn",
    "Monotonic Solution for anbn",
    "Hidden Unit Analysis for anbn"
  ],
  "Hidden Unit Dynamics for anbncn": [
    "Partly Monotonic Solution for anbncn"
  ],
  "Reber Grammar": [
    "Embedded Reber Grammar"
  ],
  "Long Short Term Memory": [
    "Gated Recurrent Unit"
  ],
  "Word Embeddings": [
    "History of Word Embeddings"
  ],
  "Singular Value Decomposition": [
    "Eigenvalue vs. Singular Value Decomposition"
  ],
  "word2vec and GloVe": [
    "word2vec 1-Word Context Model",
    "word2vec Issues",
    "word2vec Weight Updates",
    "word2vec Weight Updates",
    "word2vec Skip-Gram Model"
  ],
  "Word Analogy Task": [
    "Word Analogies"
  ],
  "Attention Mechanism": [
    "Captioning, with Attention"
  ],
  "Models of optimality": [
    "Comparing Models of Optimality"
  ],
  "Value Function": [
    "Value Function Learning"
  ],
  "Q-Learning": [
    "Q-Learning Example",
    "Theoretical Results",
    "Limitations of Theoretical Results"
  ],
  "Backgammon": [
    "Backgammon Neural Network"
  ],
  "Shock Physics": [
    "Shock Actuators",
    "Shock Sensors",
    "Shock Inputs",
    "Shock Agent",
    "Shock Task"
  ],
  "Actor-Critic": [
    "Actor Critic Algorithm"
  ],
  "Deep Q-Learning for Atari Games": [
    "DQN Results for Atari Games",
    "DQN Improvements"
  ],
  "Policy Gradients and Actor-Critic": [
    "Actor Critic Algorithm",
    "Advantage Actor Critic",
    "Asynchronous Advantage Actor Critic"
  ],
  "KL-Divergence": [
    "Reverse KL-Divergence",
    "KL-Divergence and Entropy",
    "Forward KL-Divergence",
    ""
  ],
  "Hill-Climbing": [
    "Hill-Climbing by Min-Conflicts"
  ],
  "Boltzmann Machine": [
    "Boltzmann Distribution",
    "Boltzmann Machine Limitations",
    "Restricted Boltzmann Machine",
    "Deep Boltzmann Machine"
  ],
  "Gibbs Sampling": [
    "Alternating Gibbs Sampling"
  ],
  "Contrastive Divergence": [
    "Quick Contrastive Divergence"
  ],
  "Autoencoder Networks": [
    "Autoencoder as Pretraining",
    "Regularized Autoencoders",
    "Sparse Autoencoder",
    "Contractive Autoencoder",
    "Denoising Autoencoder"
  ],
  "Variational Autoencoder": [
    "Variational Autoencoder Digits",
    "Variational Autoencoder Digits",
    "Variational Autoencoder Faces"
  ],
  "Blind Watchmaker": [
    "Blind Watchmaker Biomorphs"
  ],
  "PicBreeder": [
    "PicBreeder Examples"
  ],
  "GAN Convolutional Architectures": [
    "GAN Generated Images",
    "GAN Image Vector Arithmetic",
    "The GAN Zoo",
    "GAN References"
  ],
  "Evolutionary Computation": [
    "Evolutionary Issues"
  ],
  "Co-Evolution in Nature": [
    "Co-evolution in Machine Learning"
  ],
  "Hierarchical Evolutionary Re-Combination": [
    "Hierarchical Evolutionary Re-Combination Language (HERCL)",
    "HERCL Commands"
  ]
}

